{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test wayback internet archive API and get url util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import sys\n",
    "import json\n",
    "import lxml.html\n",
    "import csv\n",
    "from wayback import WaybackClient, memento_url_data, WaybackSession\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "REQUEST_DELAY = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request(url, session=None):\n",
    "    \"\"\"\n",
    "    Make a request to `url` and return the raw response.\n",
    "\n",
    "    This function ensure that the domain matches what is expected and that the rate limit\n",
    "    is obeyed.\n",
    "    \"\"\"\n",
    "    # check if URL starts with an allowed domain name\n",
    "    time.sleep(REQUEST_DELAY)\n",
    "    print(f\"Fetching {url}\")\n",
    "    if session:\n",
    "        resp = session.get(url)\n",
    "    else:\n",
    "        resp = requests.get(url)\n",
    "    return resp\n",
    "\n",
    "\n",
    "def make_link_absolute(rel_url, current_url):\n",
    "    \"\"\"\n",
    "    Given a relative URL like \"/abc/def\" or \"?page=2\"\n",
    "    and a complete URL like \"https://example.com/1/2/3\" this function will\n",
    "    combine the two yielding a URL like \"https://example.com/abc/def\"\n",
    "\n",
    "    Parameters:\n",
    "        * rel_url:      a URL or fragment\n",
    "        * current_url:  a complete URL used to make the request that contained a link to rel_url\n",
    "\n",
    "    Returns:\n",
    "        A full URL with protocol & domain that refers to rel_url.\n",
    "    \"\"\"\n",
    "    url = urlparse(current_url)\n",
    "    if rel_url.startswith(\"/\"):\n",
    "        return f\"{url.scheme}://{url.netloc}{rel_url}\"\n",
    "    elif rel_url.startswith(\"?\"):\n",
    "        return f\"{url.scheme}://{url.netloc}{url.path}{rel_url}\"\n",
    "    else:\n",
    "        return rel_url\n",
    "\n",
    "\n",
    "def parse_html(html):\n",
    "    \"\"\"\n",
    "    Parse HTML and return the root node.\n",
    "    \"\"\"\n",
    "    return lxml.html.fromstring(html)\n",
    "\n",
    "\n",
    "def page_grab(url, session=None):\n",
    "    response = make_request(url, session)\n",
    "    root = parse_html(response.text)\n",
    "    return root\n",
    "\n",
    "\n",
    "def create_csv(set1, title1, filename, set2=set(), title2=\"\"):\n",
    "    \"\"\"\n",
    "    turns list of articles and videos into a csv with\n",
    "    these values as respective columns.\n",
    "    args:\n",
    "    set1- items scraped (ex. article urls)\n",
    "    set2- second type of items scraped (ex. videos)\n",
    "    title1- column header for first type\n",
    "    title2- optional header for second type\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([title1, title2])\n",
    "        max_length = max(len(set1), len(set2))\n",
    "        for i in range(max_length):\n",
    "            row = [\n",
    "                list(set1)[i] if i < len(set1) else \"\",\n",
    "                list(set2)[i] if i < len(set2) else \"\",\n",
    "            ]\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "def get_urls(url, selectors, session=None):\n",
    "    \"\"\"\n",
    "    This function takes a URLs and returns lists of URLs\n",
    "    for containing each article on that page.\n",
    "\n",
    "    Parameters:\n",
    "        * url:  a URL to a page of articles\n",
    "        * session: optional session object parameter\n",
    "        * selectors: a list of css selectors\n",
    "\n",
    "    Returns:\n",
    "        A list of article URLs on that page.\n",
    "    \"\"\"\n",
    "    response = page_grab(url, session)\n",
    "    urls = []\n",
    "    for selector in selectors:\n",
    "        container = response.cssselect(selector)\n",
    "        for j in container:\n",
    "            atr = j.cssselect(\"a\")\n",
    "            if atr and len(atr) > 0:\n",
    "                href = atr[0].get(\"href\")\n",
    "                if len(href) > 0:\n",
    "                    urls.append(make_link_absolute(href, \"https://web.archive.org/\"))\n",
    "    return urls\n",
    "\n",
    "\n",
    "def crawl_wayback(homepage, break_point, scraper_func, startdate, selectors=False):\n",
    "    \"\"\"\n",
    "    Take a politics homepage, or any source with a list of articles, finds all\n",
    "    copies in the archive, and scrapes all of the article links on that page.\n",
    "    args:\n",
    "        homepage- the homepage or politics page we are looking for across time\n",
    "        break_point- the approx. number of copies in the archive\n",
    "        scraper_func - the individual function built for scraping that page\n",
    "        startdate- the date you would like to begin scraping ('YYYYMMDD')\n",
    "        selectors- optional css selector parameter(to be used with scraper_func)\n",
    "    returns:\n",
    "        list of articles from startdate to present\n",
    "\n",
    "    \"\"\"\n",
    "    session = WaybackSession()\n",
    "    client = WaybackClient(session)\n",
    "    results = client.search(homepage, match_type=\"exact\", from_date=startdate)\n",
    "    crosstime_urls = list(itertools.islice(results, break_point))\n",
    "    post_date_articles = set()\n",
    "    for i in range(len(crosstime_urls)):\n",
    "        date = datetime.datetime.strptime(startdate, \"%Y%m%d\")\n",
    "        if crosstime_urls[i].timestamp.date() >= date.date():\n",
    "            if selectors:\n",
    "                articles = scraper_func(crosstime_urls[i].view_url, selectors, session)\n",
    "            else:\n",
    "                articles = scraper_func(crosstime_urls[i].view_url, session)\n",
    "            # converts archive links back to current article links\n",
    "            articles = [memento_url_data(item)[0] for item in articles]\n",
    "            post_date_articles.update(articles)\n",
    "    return post_date_articles\n",
    "\n",
    "def crawl_wayback_2(homepage, startdate, enddate, scraper_func, selectors=False, delta_hrs= 6):\n",
    "    #Create datetime - objects to crawl using wayback\n",
    "    year, month, day = startdate\n",
    "    current_date = datetime.datetime(year,month,day)\n",
    "    year, month, day = enddate\n",
    "    end_date = datetime.datetime(year,month,day)\n",
    "    post_date_articles = set()\n",
    "\n",
    "    session = WaybackSession()\n",
    "    client = WaybackClient(session)\n",
    "\n",
    "    #Crawl interner archive once per day from startdate until enddate\n",
    "    while current_date != end_date:\n",
    "        \n",
    "        results = client.search(homepage, match_type=\"exact\", from_date=current_date)\n",
    "        record = next(results)\n",
    "        url = record.view_url\n",
    "        articles = scraper_func(url,selectors,session)\n",
    "        articles = [memento_url_data(item)[0] for item in articles]\n",
    "        post_date_articles.update(articles)\n",
    "        current_date += datetime.timedelta(days = delta_hrs)\n",
    "    return post_date_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://web.archive.org/web/20220101012450/https://www.washingtontimes.com/news/politics/?page=1\n",
      "Fetching https://web.archive.org/web/20220103060359/https://www.washingtontimes.com/news/politics/?page=1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jpmartinezclaeys/Desktop/U Chicago/James Turk - RA/newsfaces/test_wayback.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m articles\u001b[39m=\u001b[39mcrawl_wayback_2(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://www.washingtontimes.com/news/politics/?page=1\u001b[39;49m\u001b[39m\"\u001b[39;49m, [\u001b[39m2022\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m], [\u001b[39m2022\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m10\u001b[39;49m], get_urls, [\u001b[39m'\u001b[39;49m\u001b[39marticle\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "\u001b[1;32m/Users/jpmartinezclaeys/Desktop/U Chicago/James Turk - RA/newsfaces/test_wayback.ipynb Cell 4\u001b[0m in \u001b[0;36mcrawl_wayback_2\u001b[0;34m(homepage, startdate, enddate, scraper_func, selectors, delta)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=144'>145</a>\u001b[0m record \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(results)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m url \u001b[39m=\u001b[39m record\u001b[39m.\u001b[39mview_url\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m articles \u001b[39m=\u001b[39m scraper_func(url,selectors,session)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m articles \u001b[39m=\u001b[39m [memento_url_data(item)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m articles]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m post_date_articles\u001b[39m.\u001b[39mupdate(articles)\n",
      "\u001b[1;32m/Users/jpmartinezclaeys/Desktop/U Chicago/James Turk - RA/newsfaces/test_wayback.ipynb Cell 4\u001b[0m in \u001b[0;36mget_urls\u001b[0;34m(url, selectors, session)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_urls\u001b[39m(url, selectors, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39m    This function takes a URLs and returns lists of URLs\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m    for containing each article on that page.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39m        A list of article URLs on that page.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     response \u001b[39m=\u001b[39m page_grab(url, session)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     urls \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     \u001b[39mfor\u001b[39;00m selector \u001b[39min\u001b[39;00m selectors:\n",
      "\u001b[1;32m/Users/jpmartinezclaeys/Desktop/U Chicago/James Turk - RA/newsfaces/test_wayback.ipynb Cell 4\u001b[0m in \u001b[0;36mpage_grab\u001b[0;34m(url, session)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpage_grab\u001b[39m(url, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     response \u001b[39m=\u001b[39m make_request(url, session)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     root \u001b[39m=\u001b[39m parse_html(response\u001b[39m.\u001b[39mtext)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m root\n",
      "\u001b[1;32m/Users/jpmartinezclaeys/Desktop/U Chicago/James Turk - RA/newsfaces/test_wayback.ipynb Cell 4\u001b[0m in \u001b[0;36mmake_request\u001b[0;34m(url, session)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFetching \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mif\u001b[39;00m session:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     resp \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mget(url)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jpmartinezclaeys/Desktop/U%20Chicago/James%20Turk%20-%20RA/newsfaces/test_wayback.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     resp \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:542\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \n\u001b[1;32m    536\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[39m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 542\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wayback/_client.py:408\u001b[0m, in \u001b[0;36mWaybackSession.request\u001b[0;34m(self, method, url, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    407\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout\n\u001b[0;32m--> 408\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wayback/_client.py:389\u001b[0m, in \u001b[0;36mWaybackSession.send\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     seconds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackoff \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (retries \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m    388\u001b[0m     total_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m seconds\n\u001b[0;32m--> 389\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n\u001b[1;32m    391\u001b[0m retries \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "articles=crawl_wayback_2(\"https://www.washingtontimes.com/news/politics/?page=1\", [2022,1,1], [2022,1,10], get_urls, ['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://web.archive.org/web/20230101010133/https://www.nytimes.com/section/politics'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = WaybackSession()\n",
    "client = WaybackClient(session)\n",
    "results = client.search(\"https://www.nytimes.com/section/politics\", match_type=\"exact\", from_date=\"20230101\")\n",
    "record = next(results)\n",
    "record.view_url\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST get urls  and wayback with scrapers written by JP\n",
    "\n",
    "#NYT\n",
    "nyt_test = get_urls(\"https://web.archive.org/web/20230716222629/https://www.nytimes.com/section/politics\",[\"article.css-1l4spti\"])\n",
    "\n",
    "\n",
    "#Test to see how back we can go with \"articles\" as css selector\n",
    "nyt_crawler_test_23 = crawl_wayback_2(\"https://www.nytimes.com/section/politics\", [2023,1,1], [2023,1,3], get_urls, ['article'])\n",
    "print(nyt_crawler_test_23)\n",
    "nyt_crawler_test_22 = crawl_wayback_2(\"https://www.nytimes.com/section/politics\", [2022,1,1], [2022,1,3], get_urls, ['article'])\n",
    "print(nyt_crawler_test_22)\n",
    "nyt_crawler_test_21 = crawl_wayback_2(\"https://www.nytimes.com/section/politics\", [2021,1,1], [2021,1,3], get_urls, ['article'])\n",
    "print(nyt_crawler_test_21)\n",
    "nyt_crawler_test_20 = crawl_wayback_2(\"https://www.nytimes.com/section/politics\", [2020,1,1], [2020,1,3], get_urls, ['article'])\n",
    "print(nyt_crawler_test_20)\n",
    "nyt_crawler_test_19 = crawl_wayback_2(\"https://www.nytimes.com/section/politics\", [2019,1,1], [2019,1,3], get_urls, ['article'])\n",
    "print(nyt_crawler_test_19)\n",
    "nyt_crawler_test_18 = crawl_wayback_2(\"https://www.nytimes.com/section/politics\", [2018,1,1], [2018,1,3], get_urls, ['article'])\n",
    "print(nyt_crawler_test_18)\n",
    "nyt_crawler_test_17 = crawl_wayback_2(\"https://www.nytimes.com/section/politics\", [2017,1,1], [2017,1,3], get_urls, ['article'])\n",
    "print(nyt_crawler_test_17)\n",
    "nyt_crawler_test_16 = crawl_wayback_2(\"https://www.nytimes.com/section/politics\", [2016,1,1], [2016,1,3], get_urls, ['article'])\n",
    "print(nyt_crawler_test_16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_depth_wayback_crawler(homepage,  scraper_func, selectors=False, delta= False, min_year=2015, max_year=2023):\n",
    "    years = [*range(min_year,max_year+1,1)]\n",
    "    for year in reversed(years):\n",
    "        print(\"Testing year\",year)\n",
    "        startdate = [year,1,1]\n",
    "        enddate = [year,1,3]\n",
    "        year_test = crawl_wayback_2(homepage, startdate, enddate, scraper_func, selectors, delta)\n",
    "        if len(year_test) == 0:\n",
    "            return print(\"No results using this CSS selector in year\",year)\n",
    "    \n",
    "    return print(\"Selectors work for period between\",min_year, \"and\", max_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing year 2023\n",
      "Fetching https://web.archive.org/web/20230101010133/https://www.nytimes.com/section/politics\n",
      "Fetching https://web.archive.org/web/20230102001011/http://nytimes.com/section/politics\n",
      "Testing year 2022\n",
      "Fetching https://web.archive.org/web/20220101040044/https://www.nytimes.com/section/politics\n",
      "Fetching https://web.archive.org/web/20220102060757/http://nytimes.com/section/politics\n",
      "Testing year 2021\n",
      "Fetching https://web.archive.org/web/20210101010533/https://www.nytimes.com/section/politics\n",
      "Fetching https://web.archive.org/web/20210102070144/https://www.nytimes.com/section/politics\n",
      "Testing year 2020\n",
      "Fetching https://web.archive.org/web/20200101005908/https://www.nytimes.com/section/politics\n",
      "Fetching https://web.archive.org/web/20200102025944/https://www.nytimes.com/section/politics\n",
      "Testing year 2019\n",
      "Fetching https://web.archive.org/web/20190101041136/https://www.nytimes.com/section/politics\n",
      "Fetching https://web.archive.org/web/20190102013343/https://www.nytimes.com/section/politics\n",
      "Testing year 2018\n",
      "Fetching https://web.archive.org/web/20180101144534/https://www.nytimes.com/section/politics\n",
      "Fetching https://web.archive.org/web/20180102153950/https://www.nytimes.com/section/politics\n",
      "Testing year 2017\n",
      "Fetching https://web.archive.org/web/20170614233714/https://www.nytimes.com/section/politics\n",
      "Fetching https://web.archive.org/web/20170614233714/https://www.nytimes.com/section/politics\n",
      "Testing year 2016\n",
      "Fetching https://web.archive.org/web/20170614233714/https://www.nytimes.com/section/politics\n",
      "Fetching https://web.archive.org/web/20170614233714/https://www.nytimes.com/section/politics\n",
      "Testing year 2015\n",
      "Fetching https://web.archive.org/web/20170614233714/https://www.nytimes.com/section/politics\n",
      "Fetching https://web.archive.org/web/20170614233714/https://www.nytimes.com/section/politics\n",
      "Selectors work for period between 2015 and 2023\n"
     ]
    }
   ],
   "source": [
    "test_depth_wayback_crawler(\"https://www.nytimes.com/section/politics\", get_urls, ['article'],1,2015,2023)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
